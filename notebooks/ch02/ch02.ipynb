{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3章 线性神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.1.1 \n",
    "\n",
    "假设我们有一些数据$x_1, \\ldots, x_n \\in \\mathbb{R}$。我们的目标是找到一个常数$b$，使得最小化$\\sum_i (x_i - b)^2$。\n",
    "\n",
    "1. 找到最优值$b$的解析解。\n",
    "2. 这个问题及其解与正态分布有什么关系?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. $b$的最优解是$x_1, \\ldots, x_n$的平均值。这是因为$\\sum_i (x_i - b)^2 = \\sum_i (x_i - \\bar{x})^2 + n(\\bar{x} - b)^2$，其中$\\bar{x}$是$x_1, \\ldots, x_n$的平均值。由于$n(\\bar{x} - b)^2 \\geq 0$，因此当且仅当$b = \\bar{x}$时，$\\sum_i (x_i - b)^2$最小。\n",
    "    2. 这个问题与正态分布有关，因为如果我们假设$x_1, \\ldots, x_n$是从正态分布中采样得到的，那么$b = \\bar{x}$是最大似然估计下的均值。也就是说，如果我们假设数据来自正态分布，并且我们想要找到一个最好的均值来描述这些数据，那么我们应该选择样本均值作为估计量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.1.2\n",
    "\n",
    "推导出使用平方误差的线性回归优化问题的解析解。为了简化问题，可以忽略偏置$b$（我们可以通过向$\\mathbf X$添加所有值为1的一列来做到这一点）。\n",
    "\n",
    "1. 用矩阵和向量表示法写出优化问题（将所有数据视为单个矩阵，将所有目标值视为单个向量）。\n",
    "2. 计算损失对$w$的梯度。\n",
    "3. 通过将梯度设为0、求解矩阵方程来找到解析解。\n",
    "4. 什么时候可能比使用随机梯度下降更好？这种方法何时会失效？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 解答：\n",
    "    1. 设$\\mathbf X \\in \\mathbb R^{n \\times d}$是输入特征，$\\mathbf y \\in \\mathbb R^n$是标签。线性回归的目标是找到一组权重向量$\\mathbf w \\in \\mathbb R^d$，使得预测值$\\hat{\\mathbf y} = \\mathbf X\\mathbf w$与真实标签$\\mathbf y$之间的平方误差最小化。忽略偏置$b$，优化问题可以写成以下形式：\n",
    "    $$\n",
    "    \\min_{\\mathbf w} \\frac{1}{2n} \\| \\mathbf X\\mathbf w - \\mathbf y \\|_2^2.\n",
    "    $$\n",
    "\n",
    "    2. 损失函数对权重向量$\\mathbf w$的梯度为\n",
    "\n",
    "    $$\n",
    "    \\nabla_{\\mathbf w} L(\\mathbf w) = \\frac{1}{n} \\mathbf X^\\top (\\hat{\\mathbf y} - \\mathbf y).\n",
    "    $$\n",
    "\n",
    "    3. 将梯度设为0，我们得到了解析解：\n",
    "\n",
    "    $$\n",
    "    \\hat{\\mathbf w} = (\\mathbf X^\\top \\mathbf X)^{-1} \\mathbf X^\\top \\mathbf y.\n",
    "    $$\n",
    "\n",
    "    4. 当数据集较小时，解析解可能比随机梯度下降更好。然而，在大型数据集上，计算解析解可能会非常耗时，或者存在多个局部最小的情况。此外，当矩阵$\\mathbf X^\\top\\mathbf X$不可逆时，解析解不存在。在这种情况下，我们需要使用正则化或数值优化方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详细步骤：\n",
    "对于线性回归问题，损失函数是平方误差。假设我们有一个数据集$\\{(\\mathbf x_1, y_1), \\ldots, (\\mathbf x_n, y_n)\\}$，其中$\\mathbf x_i \\in \\mathbb R^d$是输入特征，$y_i \\in \\mathbb R$是标签。我们的目标是找到一组权重向量$\\mathbf w \\in \\mathbb R^d$，使得预测值$\\hat{y}_i = \\mathbf w^\\top\\mathbf x_i$与真实标签$y_i$之间的平方误差最小化。因此，损失函数可以写成以下形式：\n",
    "\n",
    "$$\n",
    "L(\\mathbf w) = \\frac{1}{2n} \\sum_{i=1}^n (\\hat{y}_i - y_i)^2 = \\frac{1}{2n} \\| \\mathbf X\\mathbf w - \\mathbf y \\|_2^2,\n",
    "$$\n",
    "\n",
    "其中$\\mathbf X = [\\mathbf x_1^\\top, \\ldots, \\mathbf x_n^\\top]^\\top$是输入特征的矩阵，$\\mathbf y = [y_1, \\ldots, y_n]^\\top$是标签向量。\n",
    "\n",
    "损失函数对权重向量$\\mathbf w$的梯度为\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf w} L(\\mathbf w) = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i) \\nabla_{\\mathbf w} \\hat{y}_i = \\frac{1}{n} \\sum_{i=1}^n (\\hat{y}_i - y_i) \\mathbf x_i,\n",
    "$$\n",
    "\n",
    "其中$\\hat{\\mathbf y} = [\\hat{y}_1, \\ldots, \\hat{y}_n]^\\top$是预测值向量。将其写成矩阵和向量表示法，我们得到：\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf w} L(\\mathbf w) =  \\frac{1}{n}  (\\hat{\\mathbf y} -  {\\mathbf y})^\\top {\\mathbf X}.\n",
    "$$\n",
    "\n",
    "因此，\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf w} L(\\mathbf w) =  \\frac{1}{n}  {\\mathbf X}^\\top (\\hat{\\mathbf y} -  {\\mathbf y}),\n",
    "$$\n",
    "\n",
    "\n",
    "我们要求解的是：$$ \\nabla_{\\mathbf w} L(\\mathbf w) = \\frac{1}{n} \\mathbf X^\\top (\\hat{\\mathbf y} - \\mathbf y) = 0 $$\n",
    "\n",
    "其中，$\\hat{\\mathbf y}$ 是预测值，$\\mathbf y$ 是真实值，$\\mathbf X$ 是输入数据。我们可以将上式变形为：\n",
    "\n",
    "$$ \\mathbf X^\\top (\\hat{\\mathbf y} - \\mathbf y) = 0 $$\n",
    "\n",
    "进一步变形得到：\n",
    "\n",
    "$$ \\mathbf X^\\top \\hat{\\mathbf y} = \\mathbf X^\\top \\mathbf y $$\n",
    "\n",
    "因为 $\\hat{\\mathbf y} = \\mathbf X\\hat{\\mathbf w}$，所以：\n",
    "\n",
    "$$ \\begin{aligned} &\\quad\\; \\mathbf X^\\top (\\hat{\\mathbf y} - \\mathbf y) = 0 \\\\ &\\Rightarrow\\; \\mathbf X^\\top ({\\mathbf X}{\\mathbf w} - \\mathbf y) = 0 \\\\ &\\Rightarrow\\; {\\mathbf w} = ({\\mathbf X}^\\top{\\mathbf X})^{-1}{\\mathbf X}^\\top\\mathbf y \\\\ \\end{aligned} $$\n",
    "\n",
    "这就是推导过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.1.3\n",
    "\n",
    "假定控制附加噪声$\\epsilon$的噪声模型是指数分布。也就是说，$p(\\epsilon) = \\frac{1}{2} \\exp(-|\\epsilon|)$\n",
    "\n",
    "1. 写出模型$-\\log P(\\mathbf y \\mid \\mathbf X)$下数据的负对数似然。\n",
    "2. 请试着写出解析解。\n",
    "3. 提出一种随机梯度下降算法来解决这个问题。哪里可能出错？（提示：当我们不断更新参数时，在驻点附近会发生什么情况）请尝试解决这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "解答\n",
    "对于高斯分布而言，其概率密度函数为：$$p(y) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(y-\\mu)^2}{2\\sigma^2}}$$ 其中μ是均值，σ是标准差。\n",
    "\n",
    "将上式取负对数并展开得到：$$-\\log p(y) = \\frac{1}{2}\\log(2\\pi\\sigma^2) + \\frac{(y-\\mu)^2}{2\\sigma^2} $$\n",
    "\n",
    "对于线性回归模型而言，它的概率密度函数为：$$p(y|x,w,b) = N(y|Xw+b,\\sigma^2)$$ 其中N表示高斯分布。\n",
    "\n",
    "因此，我们可以得到负对数似然函数的结果为：$$-\\log P(\\mathbf y \\mid \\mathbf X) = \\sum_{i=1}^n \\log p(y_i|x_i,w,b) = \\frac{n}{2}\\log(2\\pi\\sigma^2) + \\frac{1}{2\\sigma^2}||y-Xw-b||^2_2 $$\n",
    "\n",
    "其中C是一个常数，n是样本数量。\n",
    "\n",
    "因此，我们可以得到负对数似然函数的结果为：$$-\\log P(\\mathbf y \\mid \\mathbf X) = C + n\\log 2 + \\sum_{i=1}^n |\\epsilon_i|$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提出一种随机梯度下降算法来解决这个问题。哪里可能出错？（提示：当我们不断更新参数时，在驻点附近会发生什么情况）请尝试解决这个问题。\n",
    "\n",
    "- 随机梯度下降算法（SGD）是一种用于优化目标函数的迭代方法。在每次迭代中，SGD从训练集中随机选择一个样本$(\\mathbf x_i, y_i)$并计算其梯度。然后它使用该梯度来更新参数：\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  &\\mathbf w^{(t+1)} = \\mathbf w^{(t)} - \\eta_t\\nabla_{\\mathbf w} L(y_i, f(\\mathbf x_i; \\theta)), \\\\\n",
    "  &b^{(t+1)} = b^{(t)} - \\eta_t\\nabla_b L(y_i, f(\\mathbf x_i; \\theta)),\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  其中$L(y,f(\\cdot;\\theta))$是损失函数，$\\eta_t$是学习率，$\\theta=(\\mathbf w,b)$是模型参数。\n",
    "\n",
    "  在本例中，我们可以使用均方误差作为损失函数：\n",
    "  $$\n",
    "  L(y,f(\\cdot;\\theta)) = (y - (\\mathbf w^\\top\\mathbf x + b))^2.\n",
    "  $$\n",
    "\n",
    "  然而，在驻点附近可能会发生以下情况：当梯度接近零时，步长也会变得非常小，这可能导致算法收敛速度变慢。为了解决这个问题，我们可以使用一些技巧来加速收敛速度。例如，我们可以使用动量或自适应学习率等技术来加速收敛速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 线性回归的从零开始实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.1\n",
    "\n",
    "如果我们将权重初始化为零，会发生什么。算法仍然有效吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果将权重初始化为零，那么每个神经元的输出都是相同的，这意味着每个神经元学习到的参数也是相同的。因此，每个神经元都会更新相同的参数，最终导致所有神经元学习到相同的特征。因此，权重初始化为零会使算法失效。注意，线性回归把w,b全部初始化为0是不会影响的。但是，权重初始化为零会使算法失效的说法是正确的。如果将权重初始化为零，那么每个神经元的输出都是相同的，这意味着每个神经元学习到的参数也是相同的。因此，每个神经元都会更新相同的参数，最终导致所有神经元学习到相同的特征。这样就失去了神经网络的优势，即可以学习到不同特征的能力。\n",
    "\n",
    "如果在使用全零初始化时得到了最终结果，可能是因为使用了其他技巧来避免这种情况发生。例如，在训练过程中使用了正则化或者dropout等技术，这些技术可以帮助避免所有神经元学习到相同的特征。\n",
    "逻辑回归可以存在权重初始化为0，这个说法的具体解释可以参考如下链接：\n",
    "https://zhuanlan.zhihu.com/p/75879624\n",
    "逻辑回归和神经网络有不同的权重初始化方法。对于逻辑回归，可以将权重初始化为零，因为这是一个线性模型，梯度下降算法仍然可以更新它们。然而，对于神经网络来说，将权重初始化为零可能会导致对称性问题，并阻止隐藏单元学习不同的特征。因此，最好使用随机或其他方法来初始化神经网络的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.2\n",
    "\n",
    "假设试图为电压和电流的关系建立一个模型。自动微分可以用来学习模型的参数吗?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自动微分（Automatic Differentiation，简称AD）是一种对计算机程序进行高效准确求导的技术。它是介于符号微分和数值微分之间的一种方法，可以计算可导函数在某点处的导数值的计算，是反向传播算法的一般化。\n",
    "\n",
    "自动微分要解决的核心问题是计算复杂函数，通常是多层复合函数在某一点处的导数、梯度以及Hessian矩阵值\n",
    "torch中的backward就是自动微分。backward()函数会自动计算所有需要求导的变量的梯度，并将结果存储在相应变量的grad属性中。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.9330]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0252], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 生成数据\n",
    "x = torch.randn(100, 1)\n",
    "y = 3 * x + 0.5 * torch.randn(100, 1)\n",
    "\n",
    "# 定义模型\n",
    "model = torch.nn.Linear(1, 1)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 训练模型\n",
    "for epoch in range(1000):\n",
    "    # 前向传播\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # 计算损失\n",
    "    loss = criterion(y_pred, y)\n",
    "\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.3\n",
    "\n",
    "能基于[普朗克定律](https://en.wikipedia.org/wiki/Planck%27s_law)使用光谱能量密度来确定物体的温度吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "是的，可以使用普朗克定律来确定物体的温度。普朗克定律描述了黑体辐射的能量密度与温度之间的关系。通过测量物体发出的辐射能量密度，并使用普朗克定律，我们可以确定物体的温度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.4\n",
    "\n",
    "计算二阶导数时可能会遇到什么问题？这些问题可以如何解决？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在计算二阶导数时可能会遇到数值不稳定性问题。这些问题可以通过使用更高精度的数据类型（例如双精度浮点数）或通过使用数值稳定性技巧（例如中心差分）来解决。\n",
    "数值不稳定性是指在数值计算过程中，由于舍入误差、截断误差等原因，导致计算结果的精度出现大幅度波动或者发散。例如，在计算二阶导数时，如果使用简单的有限差分公式，可能会出现数值不稳定性问题。这些问题可以通过使用更高精度的数据类型（例如双精度浮点数）或通过使用数值稳定性技巧（例如中心差分）来解决。\n",
    "\n",
    "中心差分是一种常用的数值稳定性技巧，它可以用于计算函数在某个点处的导数。具体来说，中心差分可以通过以下公式计算：\n",
    "\n",
    "$$f'(x) \\approx \\frac{f(x+h)-f(x-h)}{2h}$$\n",
    "\n",
    "其中 $h$ 是一个很小的正数，通常取 $10^{-6}$ 或更小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.5\n",
    "\n",
    "为什么在`squared_loss`函数中需要使用`reshape`函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请仔细阅读书上的代码，这里使用reshape是为了保证y和y_hat形状相同，避免触发广播机制导致错误的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.6\n",
    "\n",
    "尝试使用不同的学习率，观察损失函数值下降的快慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "lr=[0.1,0.001,0.001,0.05,..]\n",
    "for lr:\n",
    "    model.train\n",
    "```\n",
    "学习率有一个最佳的取值，可以不断尝试，既不能太大，也不能太小，同时不同的模型最佳学习率也是不同的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.2.7\n",
    "\n",
    "如果样本个数不能被批量大小整除，`data_iter`函数的行为会有什么变化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果样本个数不能被批量大小整除，则在最后一个迭代周期中，最后一批次可能包含少于批量大小个样本。在这种情况下，我们只需忽略该批次中多余的样本即可。例如，1000个总样本，batch_size=3,那么最后1个样本会被舍去"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 线性回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.3.1\n",
    "\n",
    "如果将小批量的总损失替换为小批量损失的平均值，需要如何更改学习率？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果将小批量的总损失替换为小批量损失的平均值，则需要将学习率乘以批量大小。这是因为在计算梯度时，我们使用了小批量中所有样本的信息。因此，如果我们将小批量的总损失替换为小批量损失的平均值，则相当于将每个样本的梯度除以批量大小。因此，我们需要将学习率乘以批量大小，以保持相同的更新步长。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.3.2\n",
    "\n",
    "查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即\n",
    "$$\n",
    "l(y,y') = \\begin{cases}|y-y'| -\\frac{\\sigma}{2} & \\text{ if } |y-y'| > \\sigma \\\\ \\frac{1}{2 \\sigma} (y-y')^2 & \\text{ 其它情况}\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同的深度学习框架提供了不同的损失函数和初始化方法。例如，在PyTorch中，可以使用`torch.nn.MSELoss`类来计算均方误差损失，并使用`torch.nn.init.normal_`函数来初始化模型参数。要使用Huber损失代替原损失，可以自定义一个新的损失函数，并在训练过程中使用它。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.3.3\n",
    "\n",
    "如何访问线性回归的梯度？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要访问线性回归模型的梯度，可以使用自动微分技术。在PyTorch中，可以通过调用`backward()`方法来计算模型参数相对于损失函数的梯度。然后，可以通过访问模型参数的`.grad`属性来获取梯度值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 softmax回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.4.1\n",
    "\n",
    "我们可以更深入地探讨指数族与softmax之间的联系。\n",
    "\n",
    "1. 计算softmax交叉熵损失$l(\\mathbf{y},\\hat{\\mathbf{y}})$的二阶导数。\n",
    "2. 计算$\\mathrm{softmax}(\\mathbf{o})$给出的分布方差，并与上面计算的二阶导数匹配。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "l(\\mathbf{y}, \\hat{\\mathbf{y}}) &=  - \\sum_{j=1}^q y_j \\log \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} \\\\\n",
    "&= \\sum_{j=1}^q y_j \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j\\\\\n",
    "&= \\log \\sum_{k=1}^q \\exp(o_k) - \\sum_{j=1}^q y_j o_j.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "考虑相对于任何未规范化的预测$o_j$的导数，我们得到：\n",
    "\n",
    "$$\n",
    "\\partial_{o_j} l(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\exp(o_j)}{\\sum_{k=1}^q \\exp(o_k)} - y_j = \\mathrm{softmax}(\\mathbf{o})_j - y_j.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\partial_{o_j}^2 l(\\mathbf{y}, \\hat{\\mathbf{y}}) = \\frac{\\exp(o_j)*\\sum_{k=1}^q \\exp(o_k)-\\exp(o_j)^2}{(\\sum_{k=1}^q \\exp(o_k))^2}\\\\\n",
    "= \\mathrm{softmax}(\\mathbf{o})_j - (\\mathrm{softmax}(\\mathbf{o})_j)^2\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于softmax交叉熵损失函数$l(\\mathbf{y},\\hat{\\mathbf{y}})$，其二阶导数为：\n",
    "\n",
    "$$ \\begin{aligned} \\partial_{o_j}^2 l(\\mathbf{y}, \\hat{\\mathbf{y}}) &= \\mathrm{softmax}(\\mathbf{o})_j - (\\mathrm{softmax}(\\mathbf{o})_j)^2\\\\ &= \\mathrm{softmax}(\\mathbf{o})_j(1-\\mathrm{softmax}(\\mathbf{o})_j).\\\\ \\end{aligned} $$\n",
    "\n",
    "其中，$\\mathrm{softmax}(\\mathbf{o})$是由向量$\\mathbf{o}$的元素通过softmax函数计算得到的概率分布。\n",
    "\n",
    "对于softmax函数$\\mathrm{softmax}(\\mathbf{o})$，其分布方差为：\n",
    "\n",
    "$$ \\begin{aligned} \\mathrm{Var}_{\\mathrm{softmax}(\\mathbf{o})} &= \\sum_{j=1}^q (\\mathrm{softmax}(\\mathbf{o})_j - E[\\mathrm{softmax}(\\mathbf{o})_j])^2\\\\ &= \\sum_{j=1}^q (\\mathrm{softmax}(\\mathbf{o})_j - \\frac{1}{q}\\sum_{k=1}^q \\mathrm{softmax}(\\mathbf{o})_k)^2\\\\ &= \\sum_{j=1}^q (\\mathrm{softmax}(\\mathbf{o})_j - \\frac{1}{q})^2.\\\\ \\end{aligned} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.4.2\n",
    "\n",
    "假设我们有3个类发生的概率相等，即概率向量是$(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$。\n",
    "\n",
    "1. 如果我们尝试为它设计二进制代码，有什么问题？\n",
    "2. 请设计一个更好的编码。提示：如果我们尝试为两个独立的观察结果编码会发生什么？如果我们为$n$个观测值联合编码怎么办？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 假设我们有三个类发生的概率相等，即概率向量是$(\\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3})$。\n",
    "    1. 如果我们尝试为它设计二进制代码，会出现问题。因为如果我们使用两个独立的观察结果进行编码，则需要至少两个比特才能区分三个类别。但是，这意味着我们的平均长度为$\\frac{2}{3}$比特，而不是最优长度$\\log_2 3 \\approx 1.585$比特。\n",
    "    1. 我们可以使用联合编码来解决这个问题。具体来说，我们可以将$n$个观测值视为一个$n$元组，并将其映射到一个整数。例如，如果$n=2$，则可以将$(0, 0)$映射到0，$(0, 1)$映射到1，$(1, 0)$映射到2和$(1, 1)$映射到3。这样做的好处是我们可以使用$\\lceil \\log_2 3 \\rceil = 2$比特来编码三个类别。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "联合编码是一种编码方法，其中我们使用长度为$k=\\lceil \\log_2 {n+2 \\choose 2} \\rceil$的二进制代码来表示$n$个观测值的联合分布。这种方法可以用于任何概率分布，并且在实践中通常比独立编码更好。\n",
    "\n",
    "相比之下，二进制编码是一种特殊情况，其中我们尝试使用长度为$k$的二进制代码来表示一个概率向量。这种方法只适用于某些特殊的概率分布，并且在实践中可能会有问题。\n",
    "\n",
    "请注意，这些编码方法只是信息论中的两个例子，并且还有许多其他编码方法可供选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.4.3\n",
    "\n",
    "softmax是对上面介绍的映射的误称（虽然深度学习领域中很多人都使用这个名字）。真正的softmax被定义为$\\mathrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b))$。\n",
    "\n",
    "1. 证明$\\mathrm{RealSoftMax}(a, b) > \\mathrm{max}(a, b)$。\n",
    "2. 证明$\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) > \\mathrm{max}(a, b)$成立，前提是$\\lambda > 0$。\n",
    "3. 证明对于$\\lambda \\to \\infty$，有$\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) \\to \\mathrm{max}(a, b)$。\n",
    "4. softmin会是什么样子？\n",
    "5. 将其扩展到两个以上的数字。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. $\\mathrm{RealSoftMax}(a, b) = \\log (\\exp(a) + \\exp(b)) > \\log (\\exp(a)) = a$且$\\mathrm{RealSoftMax}(a, b) > b$，因此$\\mathrm{RealSoftMax}(a, b) > \\max(a,b)$。\n",
    "2. $\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) = \\lambda^{-1} \\log (\\exp(\\lambda a) + \\exp(\\lambda b)) > \\lambda^{-1} \\log (\\max(\\exp(\\lambda a),\\exp(\\lambda b))) = \\max(a,b)$，因此$\\lambda^{-1} \\mathrm{RealSoftMax}(\\lambda a, \\lambda b) > \\max(a,b)$成立，前提是$\\lambda > 0$。\n",
    "3. $\\lim_{\\lambda\\to\\infty}\\mathrm{RealSoftMax}(\\lambda a,\\lambda b)=\\lim_{\\lambda\\to\\infty}\\log(e^{\\lambda a}+e^{\\lambda b})=\\lim_{\\lambda\\to\\infty}\\log(e^{\\max(a,b)}(e^{|\\min(a,b)-\\max(a,b)|}))=\\max(a,b)$，因此对于$\\lambda\\to\\infty$，有$\\lambda^{-1}\\mathrm{RealSoftMax}(\\lambda a,\\lambda b)\\to\\max(a,b)$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmin函数是softmax函数的变体，它将输入张量的每个元素$x_i$替换为$\\exp(-x_i)$，然后对结果进行归一化。Softmin函数的公式如下：\n",
    "$$\\mathrm{Softmin}(x_i) = \\frac{\\exp(-x_i)}{\\sum_j \\exp(-x_j)}.$$\n",
    "与softmax函数类似，Softmin函数也可以用于多分类问题。不同之处在于，当输入张量中的元素越大时，Softmax函数会使输出概率越大，而Softmin函数则会使输出概率越小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 图像分类数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.5.1\n",
    "\n",
    "减少`batch_size`（如减少到1）是否会影响读取性能？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "减少`batch_size`可能会影响读取性能。具体来说，当`batch_size`减小时，每个小批量的处理时间将增加，从而导致读取性能下降。此外，较小的批量大小可能会导致内存使用率更高。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.5.2\n",
    "\n",
    "数据迭代器的性能非常重要。当前的实现足够快吗？探索各种选择来改进它。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "数据迭代器的性能对于训练深度学习模型非常重要。当前的实现可能足够快，但是我们可以探索各种选择来改进它。例如，我们可以使用多线程或异步数据读取来加速数据迭代器。此外，我们还可以使用GPU加速来加速数据预处理和增强。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.5.3\n",
    "\n",
    "查阅框架的在线API文档。还有哪些其他数据集可用？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "深度学习框架通常提供多个标准数据集，例如MNIST、CIFAR-10和ImageNet等。此外，还有许多其他数据集可用于特定领域的任务。您可以查阅框架的在线API文档以获取更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 softmax回归的从零开始实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.6.1\n",
    "\n",
    "本节直接实现了基于数学定义softmax运算的`softmax`函数。这可能会导致什么问题？提示：尝试计算$\\exp(50)$的大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 由于指数函数的值域是$(0,\\infty)$，因此可能会出现数值上溢的问题。这就是说，由于$\\exp(50)$的结果非常大，它可能超出计算机所能表示的范围，从而被近似为无穷大（inf）。这会带来一些问题，例如在反向传播时可能会出现NaN（不是数字）的情况。解决这个问题的一种常用技巧是，在计算softmax之前，先从所有输入中减去输入中的最大值。这样可以确保指数函数的输入不会太大而导致数值上溢。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.6.2\n",
    "\n",
    "本节中的函数`cross_entropy`是根据交叉熵损失函数的定义实现的。它可能有什么问题？提示：考虑对数的定义域。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 交叉熵损失函数定义了$log$函数。当模型预测概率为0时，$log$函数的值为负无穷。因此，在实践中，我们通常忽略预测概率接近0的样本对损失函数的贡献。这可能会导致模型过度自信，并且在训练期间难以收敛。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.6.3\n",
    "\n",
    "请提出一个解决方案来解决上述两个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. 解决第一个问题的方法是使用稳定版本的softmax运算。具体来说，我们可以先通过减去输入中的最大值来缩放softmax运算的输出。解决第二个问题的方法是使用交叉熵损失函数的平滑版本，例如标签平滑或温和交叉熵。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.6.4\n",
    "\n",
    "返回概率最大的分类标签总是最优解吗？例如，医疗诊断场景下可以这样做吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4. 在某些情况下，返回概率最大的分类标签可能不是最优解。例如，在医疗诊断场景下，我们更关心误诊率和漏诊率等错误类型之间的权衡。在这种情况下，我们需要考虑其他评估指标，并根据特定应用程序选择合适的阈值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.6.5\n",
    "\n",
    "假设我们使用softmax回归来预测下一个单词，可选取的单词数过多可能会带来哪些问题?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "5. 如果可选取单词数量过多，则需要计算更多参数并增加模型复杂度。此外，在训练期间需要处理更多数据，并且预测时间也会变得更长。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 补充知识：prompt分类\n",
    "今天的天气很[MASK]\n",
    "好，坏，差，行\n",
    "相当于softmax预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184705528587072e+21"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "exp(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.184705528587072e+21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., nan, 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第三题：\n",
    "x=torch.Tensor([[9,100,1]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0144e-40, 1.0000e+00, 1.0089e-43]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第三题：\n",
    "x=torch.Tensor([[9-100,100-100,1-100]])\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 softmax回归的简洁实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.7.1\n",
    "\n",
    "尝试调整超参数，例如批量大小、迭代周期数和学习率，并查看结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 练习3.7.2\n",
    "\n",
    "增加轮数，为什么测试精度会在一段时间后降低？我们怎么解决这个问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加迭代周期的数量可能会导致过拟合，从而导致测试精度下降。具体来说，当我们增加迭代周期的数量时，模型可能会开始学习到一些只能满足训练样本的非共性特征（这些更多是一种偶然性特征，不适用于测试样本），从而导致过拟合。为了解决这个问题，我们可以使用早停技术或正则化技术。早停技术是指在模型出现过拟合时（测试集表现开始下降）停止训练。正则化技术是指通过向损失函数添加惩罚项来限制模型参数的大小，从而减少过拟合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
